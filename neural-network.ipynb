{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn import metrics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n%matplotlib inline\nfrom memory_profiler import memory_usage\nimport os\nfrom glob import glob\n\nimport IPython.display as ipd\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nimport os\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint \nfrom datetime import datetime \nfrom scipy.fftpack import fft,fftfreq\nimport scipy, matplotlib.pyplot as plt, sklearn, urllib, IPython.display as ipd\nimport wave\n\n#adicionados\nfrom scipy.io import wavfile as wav\nimport struct\n\n\n#add2\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Activation, Dense\nfrom keras.utils import Sequence\n%matplotlib inline  \nimport gc\nimport pickle\nimport random\nfrom multiprocessing import Pool\n\nimport numpy as np\nimport pandas as pd\nfrom keras import optimizers, losses, activations, models\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\nfrom keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n    concatenate\nfrom numpy import random\nimport librosa\nimport numpy as np\nimport glob\nimport os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\nfrom sklearn.preprocessing import OneHotEncoder\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(signal):\n    return [       \n            librosa.feature.chroma_stft(signal).mean(),\n            librosa.feature.chroma_cqt(signal).mean(),\n            librosa.feature.chroma_cens(signal).mean(),\n            librosa.feature.mfcc(signal).mean(),\n            librosa.feature.rms(signal).mean(),\n            librosa.feature.spectral_centroid(signal).mean(),\n            librosa.feature.spectral_bandwidth(signal).mean(),\n            librosa.feature.spectral_contrast(signal).mean(),\n            librosa.feature.spectral_flatness(signal).mean(),\n            librosa.feature.zero_crossing_rate(signal).mean()\n    ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/urbansound8k/UrbanSound8K.csv\")\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_copy = data.copy()\ndata_copy.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fulldatasetpath = '../input/urbansound8k/'\n\nfull_path = []\n\n\nfor index, row in tqdm(data.iterrows()):\n    filename = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n    full_path.append(filename)\n\ndata[\"full_path\"] = full_path\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data.drop(columns=[\"slice_file_name\", \"class\"])\ndata.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_audio_signals = [librosa.load(p)[0] for p in data[\"full_path\"]]\n\n#extract features\nall_audio_signals_features = np.array([extract_features(x) for x in all_audio_signals])\n\n#normalizar features\nscaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\ntransformed_features = scaler.fit_transform(all_audio_signals_features)\ntransformed_features[np.isnan(transformed_features)]=0\ndfFeatures = pd.DataFrame(transformed_features)\ndfFeatures\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"feature_0\"] = dfFeatures[0]\ndata[\"feature_1\"] = dfFeatures[1]\ndata[\"feature_2\"] = dfFeatures[2]\ndata[\"feature_3\"] = dfFeatures[3]\ndata[\"feature_4\"] = dfFeatures[4]\ndata[\"feature_5\"] = dfFeatures[5]\ndata[\"feature_6\"] = dfFeatures[6]\ndata[\"feature_7\"] = dfFeatures[7]\ndata[\"feature_8\"] = dfFeatures[8]\ndata[\"feature_9\"] = dfFeatures[9]\n\ndata = data.drop(columns=[\"full_path\", \"fold\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(num_features):\n    \n    model = Sequential()\n    \n    model.add(Dense(100, activation='relu', input_dim=(num_features)))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(optimizer='rmsprop',\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel = get_model(10)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target = data['classID'].copy()\ndata = data.drop(columns = ['classID', 'fsID', 'start', 'end', 'salience'])\ndata.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# split train valid test\nX_train, X_test, y_train, y_test = train_test_split(\n    data, target, test_size=0.2, random_state=1)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, y_train, test_size=0.25, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stopping_monitor = EarlyStopping(patience=3)\nmodel.fit(x=X_train, y=y_train, steps_per_epoch = len(X_train), \n          validation_data=(X_val,y_val), validation_steps = len(X_val), epochs=100, verbose=1, callbacks=[early_stopping_monitor])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_result(probabilities) : \n    \n    mapping = {\n        0 : 'air_conditioner',\n        1 : 'car_horn',\n        2 : 'children_playing',\n        3 : 'dog_bark',\n        4 : 'drilling',\n        5 : 'engine_idling',\n        6 : 'gun_shot',\n        7 : 'jackhammer',\n        8 : 'siren',\n        9 : 'street_music'\n    }\n    \n    result_probability = max(probabilities)\n    index_position = np.where(probabilities == result_probability)\n    \n    actual = mapping.get(index_position[0][0])\n    print(\"Classificado como: \" + actual)\n    return actual","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_result_index(probabilities) : \n    \n    result_probability = max(probabilities)\n    index_position = np.where(probabilities == result_probability)\n    return index_position[0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\ntarget_x_test = [get_result_index(x) for x in result]\naccuracy = accuracy_score(y_test, target_x_test)\nprint(\"Acurácia: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(columns = ['Classificado como', 'Classificação real']) \ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mapping = {\n        0 : 'air_conditioner',\n        1 : 'car_horn',\n        2 : 'children_playing',\n        3 : 'dog_bark',\n        4 : 'drilling',\n        5 : 'engine_idling',\n        6 : 'gun_shot',\n        7 : 'jackhammer',\n        8 : 'siren',\n        9 : 'street_music'\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataframe_result = pd.DataFrame(result)\ndataframe_result.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classificado_como = []\n\nfor index, row in dataframe_result.iterrows():\n    classificado_como.append(get_result(row))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Classificado como'] = classificado_como\ndf['Classificação real'] = [mapping.get(index) for index in y_test]\npd.set_option('display.max_rows', df.shape[0]+1)\nprint(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef predict_audio_with_multiple_class(path, train_model):\n    \n    audio = librosa.load(path)[0]    \n    splited_audio = librosa.effects.split(audio)\n    audio_features = [extract_features(audio[x[0]:x[1]]) for x in splited_audio]\n    transformed_audio_features = scaler.fit_transform(audio_features)\n    results = train_model.predict(transformed_audio_features)\n    dataframe_result = pd.DataFrame(results)\n    classificado_como = []\n\n    for index, row in dataframe_result.iterrows():\n        classificado_como.append(get_result(row))\n        \n    return classificado_como","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fs_exemplo, data_exemplo = wav.read('../input/exemplo/exemplo.wav')\nipd.Audio(data_exemplo, rate = fs_exemplo)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_audio_with_multiple_class('../input/exemplo/exemplo.wav', model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fs_exemplo_dois, data_exemplo_dois = wav.read('../input/exemplo/exemplo2.wav')\nipd.Audio(data_exemplo_dois, rate = fs_exemplo_dois)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_audio_with_multiple_class('../input/exemplo/exemplo2.wav', model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fs_exemplo_tres, data_exemplo_tres = wav.read('../input/exemplo/exemplo3.wav')\nipd.Audio(data_exemplo_tres, rate = fs_exemplo_tres)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_audio_with_multiple_class('../input/exemplo/exemplo3.wav', model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}